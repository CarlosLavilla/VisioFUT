from pathlib import Path
from typing import Iterable, Iterator
import xml.etree.ElementTree as ET

from ultralytics import YOLO
from ultralytics.engine.results import Results, Boxes

import cv2

from utils.model.CVATElement import CVATTrack, CVATTrackedBox
from utils.model.enum import MyYoloLabel

IMG_WIDTH = 1920
IMG_HEIGHT = 1080

# Different thresholds for each category due to different difficulties on detection
CONFIDENCE_THRESHOLD: dict[MyYoloLabel, float] = {
    MyYoloLabel.PLAYER: 0.5,
    MyYoloLabel.REFEREE: 0.4,
    MyYoloLabel.BALL: 0.3,
}

KEYFRAME_CONFIDENCE_THRESHOLD: dict[MyYoloLabel, float] = {
    MyYoloLabel.PLAYER: 0.95,
    MyYoloLabel.REFEREE: 0.85,
    MyYoloLabel.BALL: 0.75,
}


class VisioFUTService:

    def __init__(self, model_path: Path) -> None:
        self._model = YOLO(str(model_path))

    def track_video(self, video_path: Path) -> Iterator[int]:
        """Makes the YOLO model predict (with tracking) in the provided video.

        Args:
            video_path (Path): path to the video that is going to be annotated by the model.

        Yields:
            Iterator[int]: progress made
        """
        results: Iterable[Results] = self._model.track(
            source=video_path, persist=True, stream=True, device=0, conf=0.25
        )

        total_frames = self._get_total_frames(video_path)

        yield from self._create_xml_predictions(
            results=results, total_frames=total_frames
        )

    def _get_total_frames(self, video_path: Path) -> int:
        """Obtains the total frames in a video.

        Args:
            video_path (Path): path to the video

        Returns:
            int: total frames in the video
        """
        cap = cv2.VideoCapture(str(video_path))
        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        cap.release()
        return total

    def _create_xml_predictions(
        self, results: Iterable[Results], total_frames: int
    ) -> Iterator[int]:
        """Processes the predictions made by the model and saves an xml file with the results in CVAT's format.

        Args:
            results (Iterable[Results]): results that the model has obtained.
            total_frames (int): total frames in the video (for progress tracking).

        Yields:
            Iterator[int]: progress made
        """
        tracks: dict[str, CVATTrack] = {}

        # Progress tracking by frames
        processed_frames: int = 0

        for frame_id, result in enumerate(results):

            boxes = result.boxes

            if boxes is None or boxes.id is None:
                continue

            self._process_frame(tracks, frame_id, boxes)

            # Increment progress
            processed_frames += 1

            # Yield percentage progress
            if total_frames is not None and total_frames > 0:
                percent: int = int((processed_frames / total_frames) * 100)
                yield min(percent, 100)
            else:
                # Fallback for indeterminate progress
                yield processed_frames

        # Post process the obtained tracks
        self._post_process_tracks(tracks, total_frames)

        xml_file: ET.ElementTree = self._generate_xml(tracks)

        xml_file.write("annotations.xml", encoding="utf-8", xml_declaration=True)

        # Complete progress
        yield 100

    def _process_frame(
        self, tracks: dict[str, CVATTrack], frame_id: int, boxes: Boxes
    ) -> None:
        """Processes a frame. Generates CVAT Tracked Boxes representations.

        Args:
            tracks (dict[str, CVATTrack]): the dictionary containing the tracks generated up to now.
            frame_id (int): id of the frame to process.
            boxes (Boxes): generated by the model.
        """
        for box_index in range(len(boxes)):
            if boxes.id is not None:
                track_id: int = int(boxes.id[box_index])
                class_id: int = int(boxes.cls[box_index])

                confidence: float = float(boxes.conf[box_index])

                if confidence < CONFIDENCE_THRESHOLD[MyYoloLabel(class_id)]:
                    continue

                xyxy = boxes.xyxy[box_index].tolist()
                x1, y1, x2, y2 = xyxy

                cvat_box: CVATTrackedBox = CVATTrackedBox(
                    frame_id,
                    x1,
                    y1,
                    x2,
                    y2,
                    keyframe=(
                        1
                        if confidence
                        >= KEYFRAME_CONFIDENCE_THRESHOLD[MyYoloLabel(class_id)]
                        else 0
                    ),
                )

                key: str = f"{class_id}-{track_id}"

                tracks.setdefault(
                    key,
                    CVATTrack(track_id, str(class_id), []),
                ).tracked_boxes.append(cvat_box)

    def _post_process_tracks(
        self, tracks: dict[str, CVATTrack], total_frames: int
    ) -> None:
        """Post processes the obtained results from the model.

        Args:
            tracks (dict[str, CVATTrack]): results obtained by the prediction model.
            total_frames (int): total frames of the video.
        """
        for track_id in tracks:
            track = tracks[track_id]
            last_keyframe = None

            # Ensure the boxes are sorted by frame
            track.tracked_boxes.sort(key=lambda b: b.frame)

            for i in range(len(track.tracked_boxes)):
                frame = track.tracked_boxes[i].frame
                if last_keyframe is None or frame - last_keyframe >= 10:
                    # Set a step keyframe for avoiding fragmentation of tracks due to interpolation
                    track.tracked_boxes[i].keyframe = 1

                if track.tracked_boxes[i].keyframe == 1:
                    last_keyframe = frame

            # First appearance of the track must be always marked as a keyframe
            track.tracked_boxes[0].keyframe = 1

            last_track_box = track.tracked_boxes[-1]
            # Last appearance of the track must be always marked as a keyframe
            last_track_box.keyframe = 1
            # Assess the outside property for the last frame of the track
            if last_track_box.frame < total_frames - 1:
                tracks[track_id].tracked_boxes.append(
                    CVATTrackedBox(
                        last_track_box.frame + 1,
                        last_track_box.xtl,
                        last_track_box.ytl,
                        last_track_box.xbr,
                        last_track_box.ybr,
                        outside=1,
                        keyframe=1,
                    )
                )
            else:
                last_track_box.outside = 0

    def _generate_xml(self, tracks: dict[str, CVATTrack]) -> ET.ElementTree:
        """Generates the CVAT 1.1 XML representation of the results obtained by the model.

        Args:
            tracks (dict[str, CVATTrack]): representation of the results obtained by the model.

        Returns:
            ET.ElementTree: XML representation of the results
        """
        # Create root XML element
        root = ET.Element("annotations")
        version = ET.SubElement(root, "version")
        version.text = "1.1"

        # Create header (metadata)
        meta = ET.SubElement(root, "meta")
        task = ET.SubElement(meta, "task")
        labels = ET.SubElement(task, "labels")

        # Place the classes
        for cls in MyYoloLabel:
            label = ET.SubElement(labels, "label")
            name = ET.SubElement(label, "name")
            name.text = cls.name.lower()

        # Place the annotations
        for key in sorted(tracks.keys()):
            _ = tracks[key].to_xml(root)

        return ET.ElementTree(root)
